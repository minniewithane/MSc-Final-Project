{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPGxKIaFTt7fPcR3Tlg5SSJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minniewithane/MSc-Final-Project/blob/main/vision_board_classfier_2_career.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Import Necessary Libraries"
      ],
      "metadata": {
        "id": "37i73BGpeZdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "\n",
        "# Tensorflow Libraries\n",
        "!pip install keras_preprocessing\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, GlobalAvgPool2D, BatchNormalization, add, Input\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
        "\n",
        "# System libraries\n",
        "import os\n",
        "import random\n",
        "from io import open\n",
        "import requests\n",
        "import shutil\n",
        "from IPython.display import Image\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from __future__ import print_function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu7ar8a-eWQ4",
        "outputId": "20be928c-8e6e-4468-93d8-c34a00e67047"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m564.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.25.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A36W2HUbseTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1282d417-287a-463e-c18c-a369166070b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#load ResNet-50\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Load the ResNet50 model with pre-trained ImageNet weights\n",
        "model = ResNet50(weights='imagenet')\n",
        "#model.summary()  # This will print the summary of the model including all layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# Generating a dummy prediction that covers all 1000 classes\n",
        "dummy_predictions = np.expand_dims(np.arange(1000), axis=0)\n",
        "\n",
        "# Decoding predictions\n",
        "decoded_classes = decode_predictions(dummy_predictions, top=1000)[0]\n",
        "for id, name, _ in decoded_classes:\n",
        "    print(f\"{id}: {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK9UD4bUvTjH",
        "outputId": "f919b65d-2fc1-44f3-aa61-9460e6ff0730",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "n15075141: toilet_tissue\n",
            "n13133613: ear\n",
            "n13054560: bolete\n",
            "n13052670: hen-of-the-woods\n",
            "n13044778: earthstar\n",
            "n13040303: stinkhorn\n",
            "n13037406: gyromitra\n",
            "n12998815: agaric\n",
            "n12985857: coral_fungus\n",
            "n12768682: buckeye\n",
            "n12620546: hip\n",
            "n12267677: acorn\n",
            "n12144580: corn\n",
            "n12057211: yellow_lady's_slipper\n",
            "n11939491: daisy\n",
            "n11879895: rapeseed\n",
            "n10565667: scuba_diver\n",
            "n10148035: groom\n",
            "n09835506: ballplayer\n",
            "n09472597: volcano\n",
            "n09468604: valley\n",
            "n09428293: seashore\n",
            "n09421951: sandbar\n",
            "n09399592: promontory\n",
            "n09332890: lakeside\n",
            "n09288635: geyser\n",
            "n09256479: coral_reef\n",
            "n09246464: cliff\n",
            "n09229709: bubble\n",
            "n09193705: alp\n",
            "n07932039: eggnog\n",
            "n07930864: cup\n",
            "n07920052: espresso\n",
            "n07892512: red_wine\n",
            "n07880968: burrito\n",
            "n07875152: potpie\n",
            "n07873807: pizza\n",
            "n07871810: meat_loaf\n",
            "n07860988: dough\n",
            "n07836838: chocolate_sauce\n",
            "n07831146: carbonara\n",
            "n07802026: hay\n",
            "n07768694: pomegranate\n",
            "n07760859: custard_apple\n",
            "n07754684: jackfruit\n",
            "n07753592: banana\n",
            "n07753275: pineapple\n",
            "n07753113: fig\n",
            "n07749582: lemon\n",
            "n07747607: orange\n",
            "n07745940: strawberry\n",
            "n07742313: Granny_Smith\n",
            "n07734744: mushroom\n",
            "n07730033: cardoon\n",
            "n07720875: bell_pepper\n",
            "n07718747: artichoke\n",
            "n07718472: cucumber\n",
            "n07717556: butternut_squash\n",
            "n07717410: acorn_squash\n",
            "n07716906: spaghetti_squash\n",
            "n07716358: zucchini\n",
            "n07715103: cauliflower\n",
            "n07714990: broccoli\n",
            "n07714571: head_cabbage\n",
            "n07711569: mashed_potato\n",
            "n07697537: hotdog\n",
            "n07697313: cheeseburger\n",
            "n07695742: pretzel\n",
            "n07693725: bagel\n",
            "n07684084: French_loaf\n",
            "n07615774: ice_lolly\n",
            "n07614500: ice_cream\n",
            "n07613480: trifle\n",
            "n07590611: hot_pot\n",
            "n07584110: consomme\n",
            "n07583066: guacamole\n",
            "n07579787: plate\n",
            "n07565083: menu\n",
            "n07248320: book_jacket\n",
            "n06874185: traffic_light\n",
            "n06794110: street_sign\n",
            "n06785654: crossword_puzzle\n",
            "n06596364: comic_book\n",
            "n06359193: web_site\n",
            "n04613696: yurt\n",
            "n04612504: yawl\n",
            "n04606251: wreck\n",
            "n04604644: worm_fence\n",
            "n04599235: wool\n",
            "n04597913: wooden_spoon\n",
            "n04596742: wok\n",
            "n04592741: wing\n",
            "n04591713: wine_bottle\n",
            "n04591157: Windsor_tie\n",
            "n04590129: window_shade\n",
            "n04589890: window_screen\n",
            "n04584207: wig\n",
            "n04579432: whistle\n",
            "n04579145: whiskey_jug\n",
            "n04562935: water_tower\n",
            "n04560804: water_jug\n",
            "n04557648: water_bottle\n",
            "n04554684: washer\n",
            "n04553703: washbasin\n",
            "n04552348: warplane\n",
            "n04550184: wardrobe\n",
            "n04548362: wallet\n",
            "n04548280: wall_clock\n",
            "n04542943: waffle_iron\n",
            "n04540053: volleyball\n",
            "n04536866: violin\n",
            "n04532670: viaduct\n",
            "n04532106: vestment\n",
            "n04525305: vending_machine\n",
            "n04525038: velvet\n",
            "n04523525: vault\n",
            "n04522168: vase\n",
            "n04517823: vacuum\n",
            "n04515003: upright\n",
            "n04509417: unicycle\n",
            "n04507155: umbrella\n",
            "n04505470: typewriter_keyboard\n",
            "n04501370: turnstile\n",
            "n04493381: tub\n",
            "n04487394: trombone\n",
            "n04487081: trolleybus\n",
            "n04486054: triumphal_arch\n",
            "n04485082: tripod\n",
            "n04483307: trimaran\n",
            "n04482393: tricycle\n",
            "n04479046: trench_coat\n",
            "n04476259: tray\n",
            "n04467665: trailer_truck\n",
            "n04465501: tractor\n",
            "n04462240: toyshop\n",
            "n04461696: tow_truck\n",
            "n04458633: totem_pole\n",
            "n04456115: torch\n",
            "n04447861: toilet_seat\n",
            "n04443257: tobacco_shop\n",
            "n04442312: toaster\n",
            "n04435653: tile_roof\n",
            "n04429376: throne\n",
            "n04428191: thresher\n",
            "n04423845: thimble\n",
            "n04418357: theater_curtain\n",
            "n04417672: thatch\n",
            "n04409515: tennis_ball\n",
            "n04404412: television\n",
            "n04399382: teddy\n",
            "n04398044: teapot\n",
            "n04392985: tape_player\n",
            "n04389033: tank\n",
            "n04380533: table_lamp\n",
            "n04376876: syringe\n",
            "n04372370: switch\n",
            "n04371774: swing\n",
            "n04371430: swimming_trunks\n",
            "n04370456: sweatshirt\n",
            "n04367480: swab\n",
            "n04366367: suspension_bridge\n",
            "n04357314: sunscreen\n",
            "n04356056: sunglasses\n",
            "n04355933: sunglass\n",
            "n04355338: sundial\n",
            "n04350905: suit\n",
            "n04347754: submarine\n",
            "n04346328: stupa\n",
            "n04344873: studio_couch\n",
            "n04336792: stretcher\n",
            "n04335435: streetcar\n",
            "n04332243: strainer\n",
            "n04330267: stove\n",
            "n04328186: stopwatch\n",
            "n04326547: stone_wall\n",
            "n04325704: stole\n",
            "n04317175: stethoscope\n",
            "n04311174: steel_drum\n",
            "n04311004: steel_arch_bridge\n",
            "n04310018: steam_locomotive\n",
            "n04296562: stage\n",
            "n04286575: spotlight\n",
            "n04285008: sports_car\n",
            "n04277352: spindle\n",
            "n04275548: spider_web\n",
            "n04273569: speedboat\n",
            "n04270147: spatula\n",
            "n04266014: space_shuttle\n",
            "n04265275: space_heater\n",
            "n04264628: space_bar\n",
            "n04263257: soup_bowl\n",
            "n04259630: sombrero\n",
            "n04258138: solar_dish\n",
            "n04254777: sock\n",
            "n04254680: soccer_ball\n",
            "n04254120: soap_dispenser\n",
            "n04252225: snowplow\n",
            "n04252077: snowmobile\n",
            "n04251144: snorkel\n",
            "n04243546: slot\n",
            "n04239074: sliding_door\n",
            "n04238763: slide_rule\n",
            "n04235860: sleeping_bag\n",
            "n04229816: ski_mask\n",
            "n04228054: ski\n",
            "n04209239: shower_curtain\n",
            "n04209133: shower_cap\n",
            "n04208210: shovel\n",
            "n04204347: shopping_cart\n",
            "n04204238: shopping_basket\n",
            "n04201297: shoji\n",
            "n04200800: shoe_shop\n",
            "n04192698: shield\n",
            "n04179913: sewing_machine\n",
            "n04162706: seat_belt\n",
            "n04154565: screwdriver\n",
            "n04153751: screw\n",
            "n04152593: screen\n",
            "n04149813: scoreboard\n",
            "n04147183: schooner\n",
            "n04146614: school_bus\n",
            "n04141975: scale\n",
            "n04141327: scabbard\n",
            "n04141076: sax\n",
            "n04136333: sarong\n",
            "n04133789: sandal\n",
            "n04131690: saltshaker\n",
            "n04127249: safety_pin\n",
            "n04125021: safe\n",
            "n04120489: running_shoe\n",
            "n04118776: rule\n",
            "n04118538: rugby_ball\n",
            "n04116512: rubber_eraser\n",
            "n04111531: rotisserie\n",
            "n04099969: rocking_chair\n",
            "n04090263: rifle\n",
            "n04086273: revolver\n",
            "n04081281: restaurant\n",
            "n04074963: remote_control\n",
            "n04070727: refrigerator\n",
            "n04069434: reflex_camera\n",
            "n04067472: reel\n",
            "n04065272: recreational_vehicle\n",
            "n04049303: rain_barrel\n",
            "n04044716: radio_telescope\n",
            "n04041544: radio\n",
            "n04040759: radiator\n",
            "n04039381: racket\n",
            "n04037443: racer\n",
            "n04033995: quilt\n",
            "n04033901: quill\n",
            "n04026417: purse\n",
            "n04023962: punching_bag\n",
            "n04019541: puck\n",
            "n04009552: projector\n",
            "n04008634: projectile\n",
            "n04005630: prison\n",
            "n04004767: printer\n",
            "n03998194: prayer_rug\n",
            "n03995372: power_drill\n",
            "n03992509: potter's_wheel\n",
            "n03991062: pot\n",
            "n03983396: pop_bottle\n",
            "n03982430: pool_table\n",
            "n03980874: poncho\n",
            "n03977966: police_van\n",
            "n03976657: pole\n",
            "n03976467: Polaroid_camera\n",
            "n03970156: plunger\n",
            "n03967562: plow\n",
            "n03961711: plate_rack\n",
            "n03958227: plastic_bag\n",
            "n03956157: planetarium\n",
            "n03954731: plane\n",
            "n03950228: pitcher\n",
            "n03947888: pirate\n",
            "n03944341: pinwheel\n",
            "n03942813: ping-pong_ball\n",
            "n03938244: pillow\n",
            "n03937543: pill_bottle\n",
            "n03935335: piggy_bank\n",
            "n03933933: pier\n",
            "n03930630: pickup\n",
            "n03930313: picket_fence\n",
            "n03929855: pickelhaube\n",
            "n03929660: pick\n",
            "n03924679: photocopier\n",
            "n03920288: Petri_dish\n",
            "n03916031: perfume\n",
            "n03908714: pencil_sharpener\n",
            "n03908618: pencil_box\n",
            "n03903868: pedestal\n",
            "n03902125: pay-phone\n",
            "n03899768: patio\n",
            "n03895866: passenger_car\n",
            "n03891332: parking_meter\n",
            "n03891251: park_bench\n",
            "n03888605: parallel_bars\n",
            "n03888257: parachute\n",
            "n03887697: paper_towel\n",
            "n03884397: panpipe\n",
            "n03877845: palace\n",
            "n03877472: pajama\n",
            "n03876231: paintbrush\n",
            "n03874599: padlock\n",
            "n03874293: paddlewheel\n",
            "n03873416: paddle\n",
            "n03871628: packet\n",
            "n03868863: oxygen_mask\n",
            "n03868242: oxcart\n",
            "n03866082: overskirt\n",
            "n03857828: oscilloscope\n",
            "n03854065: organ\n",
            "n03843555: oil_filter\n",
            "n03841143: odometer\n",
            "n03840681: ocarina\n",
            "n03838899: oboe\n",
            "n03837869: obelisk\n",
            "n03832673: notebook\n",
            "n03825788: nipple\n",
            "n03814906: necklace\n",
            "n03814639: neck_brace\n",
            "n03804744: nail\n",
            "n03803284: muzzle\n",
            "n03796401: moving_van\n",
            "n03794056: mousetrap\n",
            "n03793489: mouse\n",
            "n03792972: mountain_tent\n",
            "n03792782: mountain_bike\n",
            "n03791053: motor_scooter\n",
            "n03788365: mosquito_net\n",
            "n03788195: mosque\n",
            "n03787032: mortarboard\n",
            "n03786901: mortar\n",
            "n03785016: moped\n",
            "n03782006: monitor\n",
            "n03781244: monastery\n",
            "n03777754: modem\n",
            "n03777568: Model_T\n",
            "n03776460: mobile_home\n",
            "n03775546: mixing_bowl\n",
            "n03775071: mitten\n",
            "n03773504: missile\n",
            "n03770679: minivan\n",
            "n03770439: miniskirt\n",
            "n03769881: minibus\n",
            "n03764736: milk_can\n",
            "n03763968: military_uniform\n",
            "n03761084: microwave\n",
            "n03759954: microphone\n",
            "n03743016: megalith\n",
            "n03742115: medicine_chest\n",
            "n03733805: measuring_cup\n",
            "n03733281: maze\n",
            "n03733131: maypole\n",
            "n03729826: matchstick\n",
            "n03724870: mask\n",
            "n03721384: marimba\n",
            "n03720891: maraca\n",
            "n03717622: manhole_cover\n",
            "n03710721: maillot\n",
            "n03710637: maillot\n",
            "n03710193: mailbox\n",
            "n03709823: mailbag\n",
            "n03706229: magnetic_compass\n",
            "n03697007: lumbermill\n",
            "n03692522: loupe\n",
            "n03691459: loudspeaker\n",
            "n03690938: lotion\n",
            "n03680355: Loafer\n",
            "n03676483: lipstick\n",
            "n03673027: liner\n",
            "n03670208: limousine\n",
            "n03666591: lighter\n",
            "n03662601: lifeboat\n",
            "n03661043: library\n",
            "n03658185: letter_opener\n",
            "n03657121: lens_cap\n",
            "n03649909: lawn_mower\n",
            "n03642806: laptop\n",
            "n03637318: lampshade\n",
            "n03633091: ladle\n",
            "n03630383: lab_coat\n",
            "n03627232: knot\n",
            "n03623198: knee_pad\n",
            "n03617480: kimono\n",
            "n03602883: joystick\n",
            "n03599486: jinrikisha\n",
            "n03598930: jigsaw_puzzle\n",
            "n03595614: jersey\n",
            "n03594945: jeep\n",
            "n03594734: jean\n",
            "n03590841: jack-o'-lantern\n",
            "n03584829: iron\n",
            "n03584254: iPod\n",
            "n03544143: hourglass\n",
            "n03538406: horse_cart\n",
            "n03535780: horizontal_bar\n",
            "n03534580: hoopskirt\n",
            "n03532672: hook\n",
            "n03530642: honeycomb\n",
            "n03529860: home_theater\n",
            "n03527444: holster\n",
            "n03498962: hatchet\n",
            "n03496892: harvester\n",
            "n03495258: harp\n",
            "n03494278: harmonica\n",
            "n03492542: hard_disc\n",
            "n03485794: handkerchief\n",
            "n03485407: hand-held_computer\n",
            "n03483316: hand_blower\n",
            "n03482405: hamper\n",
            "n03481172: hammer\n",
            "n03478589: half_track\n",
            "n03476991: hair_spray\n",
            "n03476684: hair_slide\n",
            "n03467068: guillotine\n",
            "n03461385: grocery_store\n",
            "n03459775: grille\n",
            "n03457902: greenhouse\n",
            "n03452741: grand_piano\n",
            "n03450230: gown\n",
            "n03447721: gong\n",
            "n03447447: gondola\n",
            "n03445924: golfcart\n",
            "n03445777: golf_ball\n",
            "n03444034: go-kart\n",
            "n03443371: goblet\n",
            "n03425413: gas_pump\n",
            "n03424325: gasmask\n",
            "n03417042: garbage_truck\n",
            "n03404251: fur_coat\n",
            "n03400231: frying_pan\n",
            "n03394916: French_horn\n",
            "n03393912: freight_car\n",
            "n03388549: four-poster\n",
            "n03388183: fountain_pen\n",
            "n03388043: fountain\n",
            "n03384352: forklift\n",
            "n03379051: football_helmet\n",
            "n03376595: folding_chair\n",
            "n03372029: flute\n",
            "n03355925: flagpole\n",
            "n03347037: fire_screen\n",
            "n03345487: fire_engine\n",
            "n03344393: fireboat\n",
            "n03337140: file\n",
            "n03325584: feather_boa\n",
            "n03314780: face_powder\n",
            "n03297495: espresso_maker\n",
            "n03291819: envelope\n",
            "n03290653: entertainment_center\n",
            "n03272562: electric_locomotive\n",
            "n03272010: electric_guitar\n",
            "n03271574: electric_fan\n",
            "n03259280: Dutch_oven\n",
            "n03255030: dumbbell\n",
            "n03250847: drumstick\n",
            "n03249569: drum\n",
            "n03240683: drilling_platform\n",
            "n03223299: doormat\n",
            "n03220513: dome\n",
            "n03218198: dogsled\n",
            "n03216828: dock\n",
            "n03208938: disk_brake\n",
            "n03207941: dishwasher\n",
            "n03207743: dishrag\n",
            "n03201208: dining_table\n",
            "n03197337: digital_watch\n",
            "n03196217: digital_clock\n",
            "n03188531: diaper\n",
            "n03187595: dial_telephone\n",
            "n03180011: desktop_computer\n",
            "n03179701: desk\n",
            "n03160309: dam\n",
            "n03146219: cuirass\n",
            "n03141823: crutch\n",
            "n03134739: croquet_ball\n",
            "n03133878: Crock_Pot\n",
            "n03131574: crib\n",
            "n03127925: crate\n",
            "n03127747: crash_helmet\n",
            "n03126707: crane\n",
            "n03125729: cradle\n",
            "n03124170: cowboy_hat\n",
            "n03124043: cowboy_boot\n",
            "n03110669: cornet\n",
            "n03109150: corkscrew\n",
            "n03100240: convertible\n",
            "n03095699: container_ship\n",
            "n03089624: confectionery\n",
            "n03085013: computer_keyboard\n",
            "n03075370: combination_lock\n",
            "n03065424: coil\n",
            "n03063689: coffeepot\n",
            "n03063599: coffee_mug\n",
            "n03062245: cocktail_shaker\n",
            "n03047690: clog\n",
            "n03045698: cloak\n",
            "n03042490: cliff_dwelling\n",
            "n03041632: cleaver\n",
            "n03032252: cinema\n",
            "n03028079: church\n",
            "n03026506: Christmas_stocking\n",
            "n03018349: china_cabinet\n",
            "n03017168: chime\n",
            "n03016953: chiffonier\n",
            "n03014705: chest\n",
            "n03000684: chain_saw\n",
            "n03000247: chain_mail\n",
            "n03000134: chainlink_fence\n",
            "n02999410: chain\n",
            "n02992529: cellular_telephone\n",
            "n02992211: cello\n",
            "n02988304: CD_player\n",
            "n02981792: catamaran\n",
            "n02980441: castle\n",
            "n02979186: cassette_player\n",
            "n02978881: cassette\n",
            "n02977058: cash_machine\n",
            "n02974003: car_wheel\n",
            "n02971356: carton\n",
            "n02966687: carpenter's_kit\n",
            "n02966193: carousel\n",
            "n02965783: car_mirror\n",
            "n02963159: cardigan\n",
            "n02951585: can_opener\n",
            "n02951358: canoe\n",
            "n02950826: cannon\n",
            "n02948072: candle\n",
            "n02939185: caldron\n",
            "n02930766: cab\n",
            "n02927161: butcher_shop\n",
            "n02917067: bullet_train\n",
            "n02916936: bulletproof_vest\n",
            "n02910353: buckle\n",
            "n02909870: bucket\n",
            "n02906734: broom\n",
            "n02895154: breastplate\n",
            "n02894605: breakwater\n",
            "n02892767: brassiere\n",
            "n02892201: brass\n",
            "n02883205: bow_tie\n",
            "n02879718: bow\n",
            "n02877765: bottlecap\n",
            "n02871525: bookshop\n",
            "n02870880: bookcase\n",
            "n02869837: bonnet\n",
            "n02865351: bolo_tie\n",
            "n02860847: bobsled\n",
            "n02859443: boathouse\n",
            "n02843684: birdhouse\n",
            "n02841315: binoculars\n",
            "n02840245: binder\n",
            "n02837789: bikini\n",
            "n02835271: bicycle-built-for-two\n",
            "n02834397: bib\n",
            "n02825657: bell_cote\n",
            "n02823750: beer_glass\n",
            "n02823428: beer_bottle\n",
            "n02817516: bearskin\n",
            "n02815834: beaker\n",
            "n02814860: beacon\n",
            "n02814533: beach_wagon\n",
            "n02808440: bathtub\n",
            "n02808304: bath_towel\n",
            "n02807133: bathing_cap\n",
            "n02804610: bassoon\n",
            "n02804414: bassinet\n",
            "n02802426: basketball\n",
            "n02799071: baseball\n",
            "n02797295: barrow\n",
            "n02795169: barrel\n",
            "n02794156: barometer\n",
            "n02793495: barn\n",
            "n02791270: barbershop\n",
            "n02791124: barber_chair\n",
            "n02790996: barbell\n",
            "n02788148: bannister\n",
            "n02787622: banjo\n",
            "n02786058: Band_Aid\n",
            "n02783161: ballpoint\n",
            "n02782093: balloon\n",
            "n02777292: balance_beam\n",
            "n02776631: bakery\n",
            "n02769748: backpack\n",
            "n02749479: assault_rifle\n",
            "n02747177: ashcan\n",
            "n02730930: apron\n",
            "n02727426: apiary\n",
            "n02708093: analog_clock\n",
            "n02704792: amphibian\n",
            "n02701002: ambulance\n",
            "n02699494: altar\n",
            "n02692877: airship\n",
            "n02690373: airliner\n",
            "n02687172: aircraft_carrier\n",
            "n02676566: acoustic_guitar\n",
            "n02672831: accordion\n",
            "n02669723: academic_gown\n",
            "n02667093: abaya\n",
            "n02666196: abacus\n",
            "n02655020: puffer\n",
            "n02643566: lionfish\n",
            "n02641379: gar\n",
            "n02640242: sturgeon\n",
            "n02607072: anemone_fish\n",
            "n02606052: rock_beauty\n",
            "n02536864: coho\n",
            "n02526121: eel\n",
            "n02514041: barracouta\n",
            "n02510455: giant_panda\n",
            "n02509815: lesser_panda\n",
            "n02504458: African_elephant\n",
            "n02504013: Indian_elephant\n",
            "n02500267: indri\n",
            "n02497673: Madagascar_cat\n",
            "n02494079: squirrel_monkey\n",
            "n02493793: spider_monkey\n",
            "n02493509: titi\n",
            "n02492660: howler_monkey\n",
            "n02492035: capuchin\n",
            "n02490219: marmoset\n",
            "n02489166: proboscis_monkey\n",
            "n02488702: colobus\n",
            "n02488291: langur\n",
            "n02487347: macaque\n",
            "n02486410: baboon\n",
            "n02486261: patas\n",
            "n02484975: guenon\n",
            "n02483708: siamang\n",
            "n02483362: gibbon\n",
            "n02481823: chimpanzee\n",
            "n02480855: gorilla\n",
            "n02480495: orangutan\n",
            "n02457408: three-toed_sloth\n",
            "n02454379: armadillo\n",
            "n02447366: badger\n",
            "n02445715: skunk\n",
            "n02444819: otter\n",
            "n02443484: black-footed_ferret\n",
            "n02443114: polecat\n",
            "n02442845: mink\n",
            "n02441942: weasel\n",
            "n02437616: llama\n",
            "n02437312: Arabian_camel\n",
            "n02423022: gazelle\n",
            "n02422699: impala\n",
            "n02422106: hartebeest\n",
            "n02417914: ibex\n",
            "n02415577: bighorn\n",
            "n02412080: ram\n",
            "n02410509: bison\n",
            "n02408429: water_buffalo\n",
            "n02403003: ox\n",
            "n02398521: hippopotamus\n",
            "n02397096: warthog\n",
            "n02396427: wild_boar\n",
            "n02395406: hog\n",
            "n02391049: zebra\n",
            "n02389026: sorrel\n",
            "n02364673: guinea_pig\n",
            "n02363005: beaver\n",
            "n02361337: marmot\n",
            "n02356798: fox_squirrel\n",
            "n02346627: porcupine\n",
            "n02342885: hamster\n",
            "n02328150: Angora\n",
            "n02326432: hare\n",
            "n02325366: wood_rabbit\n",
            "n02321529: sea_cucumber\n",
            "n02319095: sea_urchin\n",
            "n02317335: starfish\n",
            "n02281787: lycaenid\n",
            "n02281406: sulphur_butterfly\n",
            "n02280649: cabbage_butterfly\n",
            "n02279972: monarch\n",
            "n02277742: ringlet\n",
            "n02276258: admiral\n",
            "n02268853: damselfly\n",
            "n02268443: dragonfly\n",
            "n02264363: lacewing\n",
            "n02259212: leafhopper\n",
            "n02256656: cicada\n",
            "n02236044: mantis\n",
            "n02233338: cockroach\n",
            "n02231487: walking_stick\n",
            "n02229544: cricket\n",
            "n02226429: grasshopper\n",
            "n02219486: ant\n",
            "n02206856: bee\n",
            "n02190166: fly\n",
            "n02177972: weevil\n",
            "n02174001: rhinoceros_beetle\n",
            "n02172182: dung_beetle\n",
            "n02169497: leaf_beetle\n",
            "n02168699: long-horned_beetle\n",
            "n02167151: ground_beetle\n",
            "n02165456: ladybug\n",
            "n02165105: tiger_beetle\n",
            "n02138441: meerkat\n",
            "n02137549: mongoose\n",
            "n02134418: sloth_bear\n",
            "n02134084: ice_bear\n",
            "n02133161: American_black_bear\n",
            "n02132136: brown_bear\n",
            "n02130308: cheetah\n",
            "n02129604: tiger\n",
            "n02129165: lion\n",
            "n02128925: jaguar\n",
            "n02128757: snow_leopard\n",
            "n02128385: leopard\n",
            "n02127052: lynx\n",
            "n02125311: cougar\n",
            "n02124075: Egyptian_cat\n",
            "n02123597: Siamese_cat\n",
            "n02123394: Persian_cat\n",
            "n02123159: tiger_cat\n",
            "n02123045: tabby\n",
            "n02120505: grey_fox\n",
            "n02120079: Arctic_fox\n",
            "n02119789: kit_fox\n",
            "n02119022: red_fox\n",
            "n02117135: hyena\n",
            "n02116738: African_hunting_dog\n",
            "n02115913: dhole\n",
            "n02115641: dingo\n",
            "n02114855: coyote\n",
            "n02114712: red_wolf\n",
            "n02114548: white_wolf\n",
            "n02114367: timber_wolf\n",
            "n02113978: Mexican_hairless\n",
            "n02113799: standard_poodle\n",
            "n02113712: miniature_poodle\n",
            "n02113624: toy_poodle\n",
            "n02113186: Cardigan\n",
            "n02113023: Pembroke\n",
            "n02112706: Brabancon_griffon\n",
            "n02112350: keeshond\n",
            "n02112137: chow\n",
            "n02112018: Pomeranian\n",
            "n02111889: Samoyed\n",
            "n02111500: Great_Pyrenees\n",
            "n02111277: Newfoundland\n",
            "n02111129: Leonberg\n",
            "n02110958: pug\n",
            "n02110806: basenji\n",
            "n02110627: affenpinscher\n",
            "n02110341: dalmatian\n",
            "n02110185: Siberian_husky\n",
            "n02110063: malamute\n",
            "n02109961: Eskimo_dog\n",
            "n02109525: Saint_Bernard\n",
            "n02109047: Great_Dane\n",
            "n02108915: French_bulldog\n",
            "n02108551: Tibetan_mastiff\n",
            "n02108422: bull_mastiff\n",
            "n02108089: boxer\n",
            "n02108000: EntleBucher\n",
            "n02107908: Appenzeller\n",
            "n02107683: Bernese_mountain_dog\n",
            "n02107574: Greater_Swiss_Mountain_dog\n",
            "n02107312: miniature_pinscher\n",
            "n02107142: Doberman\n",
            "n02106662: German_shepherd\n",
            "n02106550: Rottweiler\n",
            "n02106382: Bouvier_des_Flandres\n",
            "n02106166: Border_collie\n",
            "n02106030: collie\n",
            "n02105855: Shetland_sheepdog\n",
            "n02105641: Old_English_sheepdog\n",
            "n02105505: komondor\n",
            "n02105412: kelpie\n",
            "n02105251: briard\n",
            "n02105162: malinois\n",
            "n02105056: groenendael\n",
            "n02104365: schipperke\n",
            "n02104029: kuvasz\n",
            "n02102973: Irish_water_spaniel\n",
            "n02102480: Sussex_spaniel\n",
            "n02102318: cocker_spaniel\n",
            "n02102177: Welsh_springer_spaniel\n",
            "n02102040: English_springer\n",
            "n02101556: clumber\n",
            "n02101388: Brittany_spaniel\n",
            "n02101006: Gordon_setter\n",
            "n02100877: Irish_setter\n",
            "n02100735: English_setter\n",
            "n02100583: vizsla\n",
            "n02100236: German_short-haired_pointer\n",
            "n02099849: Chesapeake_Bay_retriever\n",
            "n02099712: Labrador_retriever\n",
            "n02099601: golden_retriever\n",
            "n02099429: curly-coated_retriever\n",
            "n02099267: flat-coated_retriever\n",
            "n02098413: Lhasa\n",
            "n02098286: West_Highland_white_terrier\n",
            "n02098105: soft-coated_wheaten_terrier\n",
            "n02097658: silky_terrier\n",
            "n02097474: Tibetan_terrier\n",
            "n02097298: Scotch_terrier\n",
            "n02097209: standard_schnauzer\n",
            "n02097130: giant_schnauzer\n",
            "n02097047: miniature_schnauzer\n",
            "n02096585: Boston_bull\n",
            "n02096437: Dandie_Dinmont\n",
            "n02096294: Australian_terrier\n",
            "n02096177: cairn\n",
            "n02096051: Airedale\n",
            "n02095889: Sealyham_terrier\n",
            "n02095570: Lakeland_terrier\n",
            "n02095314: wire-haired_fox_terrier\n",
            "n02094433: Yorkshire_terrier\n",
            "n02094258: Norwich_terrier\n",
            "n02094114: Norfolk_terrier\n",
            "n02093991: Irish_terrier\n",
            "n02093859: Kerry_blue_terrier\n",
            "n02093754: Border_terrier\n",
            "n02093647: Bedlington_terrier\n",
            "n02093428: American_Staffordshire_terrier\n",
            "n02093256: Staffordshire_bullterrier\n",
            "n02092339: Weimaraner\n",
            "n02092002: Scottish_deerhound\n",
            "n02091831: Saluki\n",
            "n02091635: otterhound\n",
            "n02091467: Norwegian_elkhound\n",
            "n02091244: Ibizan_hound\n",
            "n02091134: whippet\n",
            "n02091032: Italian_greyhound\n",
            "n02090721: Irish_wolfhound\n",
            "n02090622: borzoi\n",
            "n02090379: redbone\n",
            "n02089973: English_foxhound\n",
            "n02089867: Walker_hound\n",
            "n02089078: black-and-tan_coonhound\n",
            "n02088632: bluetick\n",
            "n02088466: bloodhound\n",
            "n02088364: beagle\n",
            "n02088238: basset\n",
            "n02088094: Afghan_hound\n",
            "n02087394: Rhodesian_ridgeback\n",
            "n02087046: toy_terrier\n",
            "n02086910: papillon\n",
            "n02086646: Blenheim_spaniel\n",
            "n02086240: Shih-Tzu\n",
            "n02086079: Pekinese\n",
            "n02085936: Maltese_dog\n",
            "n02085782: Japanese_spaniel\n",
            "n02085620: Chihuahua\n",
            "n02077923: sea_lion\n",
            "n02074367: dugong\n",
            "n02071294: killer_whale\n",
            "n02066245: grey_whale\n",
            "n02058221: albatross\n",
            "n02056570: king_penguin\n",
            "n02051845: pelican\n",
            "n02037110: oystercatcher\n",
            "n02033041: dowitcher\n",
            "n02028035: redshank\n",
            "n02027492: red-backed_sandpiper\n",
            "n02025239: ruddy_turnstone\n",
            "n02018795: bustard\n",
            "n02018207: American_coot\n",
            "n02017213: European_gallinule\n",
            "n02013706: limpkin\n",
            "n02012849: crane\n",
            "n02011460: bittern\n",
            "n02009912: American_egret\n",
            "n02009229: little_blue_heron\n",
            "n02007558: flamingo\n",
            "n02006656: spoonbill\n",
            "n02002724: black_stork\n",
            "n02002556: white_stork\n",
            "n01990800: isopod\n",
            "n01986214: hermit_crab\n",
            "n01985128: crayfish\n",
            "n01984695: spiny_lobster\n",
            "n01983481: American_lobster\n",
            "n01981276: king_crab\n",
            "n01980166: fiddler_crab\n",
            "n01978455: rock_crab\n",
            "n01978287: Dungeness_crab\n",
            "n01968897: chambered_nautilus\n",
            "n01955084: chiton\n",
            "n01950731: sea_slug\n",
            "n01945685: slug\n",
            "n01944390: snail\n",
            "n01943899: conch\n",
            "n01930112: nematode\n",
            "n01924916: flatworm\n",
            "n01917289: brain_coral\n",
            "n01914609: sea_anemone\n",
            "n01910747: jellyfish\n",
            "n01883070: wombat\n",
            "n01882714: koala\n",
            "n01877812: wallaby\n",
            "n01873310: platypus\n",
            "n01872401: echidna\n",
            "n01871265: tusker\n",
            "n01860187: black_swan\n",
            "n01855672: goose\n",
            "n01855032: red-breasted_merganser\n",
            "n01847000: drake\n",
            "n01843383: toucan\n",
            "n01843065: jacamar\n",
            "n01833805: hummingbird\n",
            "n01829413: hornbill\n",
            "n01828970: bee_eater\n",
            "n01824575: coucal\n",
            "n01820546: lorikeet\n",
            "n01819313: sulphur-crested_cockatoo\n",
            "n01818515: macaw\n",
            "n01817953: African_grey\n",
            "n01807496: partridge\n",
            "n01806567: quail\n",
            "n01806143: peacock\n",
            "n01798484: prairie_chicken\n",
            "n01797886: ruffed_grouse\n",
            "n01796340: ptarmigan\n",
            "n01795545: black_grouse\n",
            "n01784675: centipede\n",
            "n01776313: tick\n",
            "n01775062: wolf_spider\n",
            "n01774750: tarantula\n",
            "n01774384: black_widow\n",
            "n01773797: garden_spider\n",
            "n01773549: barn_spider\n",
            "n01773157: black_and_gold_garden_spider\n",
            "n01770393: scorpion\n",
            "n01770081: harvestman\n",
            "n01768244: trilobite\n",
            "n01756291: sidewinder\n",
            "n01755581: diamondback\n",
            "n01753488: horned_viper\n",
            "n01751748: sea_snake\n",
            "n01749939: green_mamba\n",
            "n01748264: Indian_cobra\n",
            "n01744401: rock_python\n",
            "n01742172: boa_constrictor\n",
            "n01740131: night_snake\n",
            "n01739381: vine_snake\n",
            "n01737021: water_snake\n",
            "n01735189: garter_snake\n",
            "n01734418: king_snake\n",
            "n01729977: green_snake\n",
            "n01729322: hognose_snake\n",
            "n01728920: ringneck_snake\n",
            "n01728572: thunder_snake\n",
            "n01704323: triceratops\n",
            "n01698640: American_alligator\n",
            "n01697457: African_crocodile\n",
            "n01695060: Komodo_dragon\n",
            "n01694178: African_chameleon\n",
            "n01693334: green_lizard\n",
            "n01692333: Gila_monster\n",
            "n01689811: alligator_lizard\n",
            "n01688243: frilled_lizard\n",
            "n01687978: agama\n",
            "n01685808: whiptail\n",
            "n01682714: American_chameleon\n",
            "n01677366: common_iguana\n",
            "n01675722: banded_gecko\n",
            "n01669191: box_turtle\n",
            "n01667778: terrapin\n",
            "n01667114: mud_turtle\n",
            "n01665541: leatherback_turtle\n",
            "n01664065: loggerhead\n",
            "n01644900: tailed_frog\n",
            "n01644373: tree_frog\n",
            "n01641577: bullfrog\n",
            "n01632777: axolotl\n",
            "n01632458: spotted_salamander\n",
            "n01631663: eft\n",
            "n01630670: common_newt\n",
            "n01629819: European_fire_salamander\n",
            "n01622779: great_grey_owl\n",
            "n01616318: vulture\n",
            "n01614925: bald_eagle\n",
            "n01608432: kite\n",
            "n01601694: water_ouzel\n",
            "n01592084: chickadee\n",
            "n01582220: magpie\n",
            "n01580077: jay\n",
            "n01560419: bulbul\n",
            "n01558993: robin\n",
            "n01537544: indigo_bunting\n",
            "n01534433: junco\n",
            "n01532829: house_finch\n",
            "n01531178: goldfinch\n",
            "n01530575: brambling\n",
            "n01518878: ostrich\n",
            "n01514859: hen\n",
            "n01514668: cock\n",
            "n01498041: stingray\n",
            "n01496331: electric_ray\n",
            "n01494475: hammerhead\n",
            "n01491361: tiger_shark\n",
            "n01484850: great_white_shark\n",
            "n01443537: goldfish\n",
            "n01440764: tench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#所有需要的內容 Set up environment\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "Bz-V8hC1vXZH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class KaggleDataset(Dataset):\n",
        "#     def __init__(self, csv_file, root_dir, transform=None):\n",
        "# self.annotations = pd.read_csv(csv_file)\n",
        "#         self.root_dir = root_dir\n",
        "#         self.transform = None\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.annotations)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "#         image = Image.open(img_path).convert(\"RGB\")\n",
        "#         y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "\n",
        "#         if self.transform:\n",
        "\n",
        "#         return (image, y_label)"
      ],
      "metadata": {
        "id": "Y5ngK1qOcfrD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 3: Set up data transformations\n",
        "# data_transforms = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])"
      ],
      "metadata": {
        "id": "pmdoK5chcvUv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbUaANPDdKGr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparing"
      ],
      "metadata": {
        "id": "UZe4EyqXz3e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/My Drive/Birmingham/Final Project/image data 2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcFCZGXI0ot3",
        "outputId": "dd7277e2-894b-4756-9d98-a05ee7fb1848"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "# List all class directories\n",
        "class_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "# show all the directories\n",
        "class_dirs"
      ],
      "metadata": {
        "id": "BNi_cniYz9mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b92e568-7556-4b76-ff72-c8a63e374614"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2_police',\n",
              " '2_waiter',\n",
              " '2_chef',\n",
              " '2_doctor',\n",
              " '2_engineer',\n",
              " '2_farmer',\n",
              " '2_firefighter',\n",
              " '2_judge',\n",
              " '2_mechanic',\n",
              " '2_pilot']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data augmentation for small data\n",
        "\n",
        "\n",
        "*   family/male friend/female friend/mix friend\n",
        "*   meditation/yoga_downdog/yoga_goddess/yoga_plank/yoga_warrior\n",
        "*   chef/doctor/engineer/farmer/firefighter/judge/mechanic/pilot/police/waiter\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GrUkkKOiNPKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "# from tensorflow.keras.applications import ResNet50\n",
        "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=40,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "\n",
        "# # 设置数据路径\n",
        "# data_dir = '/content/drive/MyDrive/Birmingham/Final Project/image data 2/'\n",
        "# # categories_to_augment = ['2_male_celebrity']  # 需要增強的類別\n",
        "\n",
        "# # 创建数据生成器\n",
        "# for category in class_dirs:\n",
        "#     category_path = os.path.join(data_dir, category)\n",
        "#     images = os.listdir(category_path)\n",
        "\n",
        "#     for image_name in images:\n",
        "#         image_path = os.path.join(category_path, image_name)\n",
        "#         img = load_img(image_path)\n",
        "#         x = img_to_array(img)\n",
        "#         x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#         # 生成並保存增強圖片\n",
        "#         i = 0\n",
        "#         for batch in datagen.flow(x, batch_size=1, save_to_dir=category_path, save_prefix='aug', save_format='jpeg'):\n",
        "#             i += 1\n",
        "#             if i >= 1:  # 生成2倍的增強數據，即使總數據量達到原來的3倍\n",
        "#                 break"
      ],
      "metadata": {
        "id": "HARP2l7DOnPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a2114406-3251-491e-b6f0-82759648eec3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7f66c7d53740>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b5f237aa475e>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f66c7d53740>"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import random\n",
        "# List all class directories\n",
        "class_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "# show all the directories\n",
        "class_dirs\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 设置数据路径\n",
        "data_dir = '/content/drive/MyDrive/Birmingham/Final Project/image data 2/'\n",
        "# categories_to_augment = ['2_male_celebrity']  # 需要增強的類別\n",
        "\n",
        "# 创建数据生成器\n",
        "for category in class_dirs:\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    images = os.listdir(category_path)\n",
        "\n",
        "    for image_name in images:\n",
        "        # Check if the file is a valid image file\n",
        "        if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  # Add more extensions if needed\n",
        "            continue  # Skip to the next file if it's not an image\n",
        "\n",
        "        image_path = os.path.join(category_path, image_name)\n",
        "        img = load_img(image_path)\n",
        "        x = img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        # 生成並保存增強圖片\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=category_path, save_prefix='aug', save_format='jpeg'):\n",
        "            i += 1\n",
        "            if i >= 1:  # 生成2倍的增強數據，即使總數據量達到原來的3倍\n",
        "                break"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EM1JjmHABdKf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split to train / val / test set\n",
        "\n",
        "generate a new folder : split_data - move to there, train data there"
      ],
      "metadata": {
        "id": "_IhRq0tLZ476"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create directories for train and test data\n",
        "# data_dir = '/content/drive/MyDrive/Birmingham/Final Project/image data/'\n",
        "# train_dir = os.path.join(data_dir, 'train')\n",
        "# val_dir = os.path.join(data_dir, 'val')\n",
        "# test_dir = os.path.join(data_dir, 'test')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# # Number of images to select per class\n",
        "# random.seed(42)  # Set the random seed for reproducibility\n",
        "# num_images_per_class = 1000\n",
        "\n",
        "# # Loop through each class directory\n",
        "# for class_dir in class_dirs:\n",
        "#     # Create directories for train, validation and test data within each class\n",
        "#     train_class_dir = os.path.join(train_dir, class_dir)\n",
        "#     val_class_dir = os.path.join(val_dir, class_dir)\n",
        "#     test_class_dir = os.path.join(test_dir, class_dir)\n",
        "#     os.makedirs(train_class_dir, exist_ok=True)\n",
        "#     os.makedirs(val_class_dir, exist_ok=True)\n",
        "#     os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "#     # List all images in the current class directory\n",
        "#     images = os.listdir(os.path.join(data_dir, class_dir))\n",
        "#     print(f\"Class: {class_dir}, Number of images: {len(images)}\")\n",
        "\n",
        "#     # Sample a maximum of `num_images_per_class` images, or all images if there are fewer\n",
        "#     num_images_to_sample = min(num_images_per_class, len(images))\n",
        "#     selected_images = random.sample(images, num_images_to_sample)\n",
        "\n",
        "#     # Move the selected images to train(70%), val(10%), and test(20%) directories\n",
        "#     for image in selected_images:\n",
        "#         src_path = os.path.join(data_dir, class_dir, image)\n",
        "#         if image in random.sample(selected_images, int(num_images_to_sample * 0.7)):  # 70% for training\n",
        "#             dst_path = os.path.join(train_class_dir, image)\n",
        "#         elif image in random.sample(selected_images, int(num_images_to_sample * 0.1)):  # 10% for validation\n",
        "#             dst_path = os.path.join(val_class_dir, image)\n",
        "#         else:  # 20% for testing\n",
        "#             dst_path = os.path.join(test_class_dir, image)\n",
        "#         shutil.copy(src_path, dst_path) # Don't forget to copy the file!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ktD3tWM3fG",
        "outputId": "7f5d5389-caf8-4001-b081-fa620ae4b1ec",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/drive/MyDrive/Birmingham/Final Project/image data/train/1_female_friend'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-86b17253bcbf>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 20% for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_class_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Don't forget to copy the file!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/Birmingham/Final Project/image data/train/1_female_friend'"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Create directories for train and test data OUTSIDE the original data directory\n",
        "data_dir = '/content/drive/MyDrive/Birmingham/Final Project/image data 2/'\n",
        "split_data_dir = '/content/drive/MyDrive/Birmingham/Final Project/split_data 2/' # New directory for split data\n",
        "train_dir = os.path.join(split_data_dir, 'train')\n",
        "val_dir = os.path.join(split_data_dir, 'val')\n",
        "test_dir = os.path.join(split_data_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Number of images to select per class\n",
        "random.seed(42)  # Set the random seed for reproducibility\n",
        "num_images_per_class = 1000\n",
        "\n",
        "# Loop through each class directory\n",
        "for class_dir in class_dirs:\n",
        "    # Create directories for train, validation and test data within each class\n",
        "    train_class_dir = os.path.join(train_dir, class_dir)\n",
        "    val_class_dir = os.path.join(val_dir, class_dir)\n",
        "    test_class_dir = os.path.join(test_dir, class_dir)\n",
        "    os.makedirs(train_class_dir, exist_ok=True)\n",
        "    os.makedirs(val_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "    # List all images in the current class directory, excluding directories\n",
        "    images = [img for img in os.listdir(os.path.join(data_dir, class_dir)) if os.path.isfile(os.path.join(data_dir, class_dir, img))]\n",
        "    print(f\"Class: {class_dir}, Number of images: {len(images)}\")\n",
        "\n",
        "    # Sample a maximum of `num_images_per_class` images, or all images if there are fewer\n",
        "    num_images_to_sample = min(num_images_per_class, len(images))\n",
        "    selected_images = random.sample(images, num_images_to_sample)\n",
        "\n",
        "    # Move the selected images to train(70%), val(10%), and test(20%) directories\n",
        "    for image in selected_images:\n",
        "        src_path = os.path.join(data_dir, class_dir, image)\n",
        "        if image in random.sample(selected_images, int(num_images_to_sample * 0.7)):  # 70% for training\n",
        "            dst_path = os.path.join(train_class_dir, image)\n",
        "        elif image in random.sample(selected_images, int(num_images_to_sample * 0.1)):  # 10% for validation\n",
        "            dst_path = os.path.join(val_class_dir, image)\n",
        "        else:  # 20% for testing\n",
        "            dst_path = os.path.join(test_class_dir, image)\n",
        "        shutil.copy(src_path, dst_path) # Copy the file to the new location"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1PmKFySMWud",
        "outputId": "e12404ad-8ef9-400f-c156-7d1d49f09872"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 2_police, Number of images: 1785\n",
            "Class: 2_waiter, Number of images: 1765\n",
            "Class: 2_chef, Number of images: 1754\n",
            "Class: 2_doctor, Number of images: 1761\n",
            "Class: 2_engineer, Number of images: 1754\n",
            "Class: 2_farmer, Number of images: 1747\n",
            "Class: 2_firefighter, Number of images: 1770\n",
            "Class: 2_judge, Number of images: 1764\n",
            "Class: 2_mechanic, Number of images: 1758\n",
            "Class: 2_pilot, Number of images: 1766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tune ResNet50"
      ],
      "metadata": {
        "id": "23Sa-GZ--KCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random.seed(42)\n",
        "# np.random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # 加載預訓練的 ResNet50 模型，不包括頂部的分類層\n",
        "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# # 添加新的分類層\n",
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(1024, activation='relu')(x)\n",
        "# num_new_class = 9  # 新的類別數量, 每次TRAIN記得要改\n",
        "\n",
        "# # predictions = Dense(num_new_class , activation='softmax')(x)  # 1000個原始類別 + 新的類別\n",
        "# # model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# predictions_new = Dense(num_new_class, activation='softmax')(x)\n",
        "# model_new_classes = Model(inputs=base_model.input, outputs=predictions_new)\n",
        "\n",
        "# # 冻结所有卷积基模型的层\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model_new_classes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#                          loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # 準備數據生成器，並預處理圖像\n",
        "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "# valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# valid_generator = valid_datagen.flow_from_directory(\n",
        "#     val_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "\n",
        "# # 訓練模型\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10,\n",
        "#     validation_data=valid_generator,\n",
        "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "#     validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        "# )\n",
        "\n",
        "# # 解冻部分卷积层进行细调\n",
        "# for layer in base_model.layers[:143]:\n",
        "#     layer.trainable = False\n",
        "# for layer in base_model.layers[143:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_fine = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10,\n",
        "#     validation_data=valid_generator,\n",
        "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "#     validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        "# )\n",
        "\n",
        "# # 保存模型\n",
        "# model.save('/content/drive/MyDrive/classifier_v1_1.h5')\n"
      ],
      "metadata": {
        "id": "wUonYQqv9iIR",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "train_dir =  '/content/drive/MyDrive/Birmingham/Final Project/split_data 2/train'\n",
        "val_dir =  '/content/drive/MyDrive/Birmingham/Final Project/split_data 2/val'\n",
        "test_dir =  '/content/drive/MyDrive/Birmingham/Final Project/split_data 2/test'\n",
        "\n",
        "# 加載預訓練的 ResNet50 模型，不包括頂部的分類層\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 添加新的分類層\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "num_new_class = 10  # 新的類別數量, 每次TRAIN記得要改\n",
        "\n",
        "# predictions = Dense(num_new_class , activation='softmax')(x)  # 1000個原始類別 + 新的類別\n",
        "# model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "predictions_new = Dense(num_new_class, activation='softmax')(x)\n",
        "model_new_classes = Model(inputs=base_model.input, outputs=predictions_new)\n",
        "\n",
        "# 冻结所有卷积基模型的层\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_new_classes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                         loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# 準備數據生成器，並預處理圖像\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "# 訓練模型\n",
        "history = model_new_classes.fit( # Changed 'model' to 'model_new_classes'\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        ")\n",
        "\n",
        "# 解冻部分卷积层进行细调\n",
        "for layer in base_model.layers[:143]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[143:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_new_classes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy']) # Changed 'model' to 'model_new_classes'\n",
        "\n",
        "history_fine = model_new_classes.fit( # Changed 'model' to 'model_new_classes'\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        ")\n",
        "\n",
        "# 保存模型\n",
        "model_new_classes.save('/content/drive/MyDrive/classifier_v1_2.h5') # Changed 'model' to 'model_new_classes'"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki-iNb7S-0I3",
        "outputId": "1f86f7a7-9381-4de1-8699-ed59a45ea274"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6956 images belonging to 10 classes.\n",
            "Found 292 images belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "217/217 [==============================] - 32s 130ms/step - loss: 0.7569 - accuracy: 0.7642 - val_loss: 0.5561 - val_accuracy: 0.7847\n",
            "Epoch 2/10\n",
            "217/217 [==============================] - 27s 125ms/step - loss: 0.3768 - accuracy: 0.8729 - val_loss: 0.5090 - val_accuracy: 0.7917\n",
            "Epoch 3/10\n",
            "217/217 [==============================] - 27s 122ms/step - loss: 0.2684 - accuracy: 0.9058 - val_loss: 0.6559 - val_accuracy: 0.7778\n",
            "Epoch 4/10\n",
            "217/217 [==============================] - 27s 126ms/step - loss: 0.1864 - accuracy: 0.9376 - val_loss: 0.5419 - val_accuracy: 0.8264\n",
            "Epoch 5/10\n",
            "217/217 [==============================] - 27s 124ms/step - loss: 0.1210 - accuracy: 0.9575 - val_loss: 0.5427 - val_accuracy: 0.8194\n",
            "Epoch 6/10\n",
            "217/217 [==============================] - 27s 124ms/step - loss: 0.0800 - accuracy: 0.9746 - val_loss: 0.6812 - val_accuracy: 0.8090\n",
            "Epoch 7/10\n",
            "217/217 [==============================] - 27s 124ms/step - loss: 0.0747 - accuracy: 0.9749 - val_loss: 0.5763 - val_accuracy: 0.8299\n",
            "Epoch 8/10\n",
            "217/217 [==============================] - 27s 124ms/step - loss: 0.0406 - accuracy: 0.9889 - val_loss: 0.6846 - val_accuracy: 0.8264\n",
            "Epoch 9/10\n",
            "217/217 [==============================] - 27s 126ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.7151 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "217/217 [==============================] - 26s 121ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.5783 - val_accuracy: 0.8576\n",
            "Epoch 1/10\n",
            "217/217 [==============================] - 38s 130ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.5739 - val_accuracy: 0.8403\n",
            "Epoch 2/10\n",
            "217/217 [==============================] - 27s 126ms/step - loss: 0.0251 - accuracy: 0.9949 - val_loss: 0.5421 - val_accuracy: 0.8472\n",
            "Epoch 3/10\n",
            "217/217 [==============================] - 28s 127ms/step - loss: 0.0130 - accuracy: 0.9990 - val_loss: 0.5313 - val_accuracy: 0.8611\n",
            "Epoch 4/10\n",
            "217/217 [==============================] - 27s 125ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 0.5475 - val_accuracy: 0.8611\n",
            "Epoch 5/10\n",
            "217/217 [==============================] - 27s 125ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.5288 - val_accuracy: 0.8646\n",
            "Epoch 6/10\n",
            "217/217 [==============================] - 28s 127ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.5065 - val_accuracy: 0.8715\n",
            "Epoch 7/10\n",
            "217/217 [==============================] - 27s 125ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.4942 - val_accuracy: 0.8785\n",
            "Epoch 8/10\n",
            "217/217 [==============================] - 28s 127ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8681\n",
            "Epoch 9/10\n",
            "217/217 [==============================] - 27s 123ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.5014 - val_accuracy: 0.8646\n",
            "Epoch 10/10\n",
            "217/217 [==============================] - 27s 124ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.5118 - val_accuracy: 0.8611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#壞掉的code"
      ],
      "metadata": {
        "id": "hqICyAdX8_YA"
      }
    },
    {
      "source": [
        "# random.seed(42)\n",
        "# np.random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # Load the pre-trained ResNet50 model, including the top classification layer\n",
        "# base_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Get the output of the penultimate layer (before the final softmax)\n",
        "# x = base_model.layers[-2].output\n",
        "\n",
        "# # Add new classification layer for the new classes\n",
        "# num_new_class = 9\n",
        "# new_class_predictions = Dense(num_new_class, activation='softmax', name='new_class_output')(x)\n",
        "\n",
        "# # Create a new model with two outputs: original 1000 classes and new 9 classes\n",
        "# model = Model(inputs=base_model.input, outputs=[base_model.output, new_class_predictions])\n",
        "\n",
        "# # Freeze all layers in the base model except the new classification layer\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "# model.get_layer('new_class_output').trainable = True  # Make the new layer trainable\n",
        "\n",
        "# # Compile the model with appropriate loss functions for both outputs\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#     loss={\n",
        "#         'predictions': 'categorical_crossentropy',  # Original 1000 classes\n",
        "#         'new_class_output': 'categorical_crossentropy'  # New 9 classes\n",
        "#     },\n",
        "#     loss_weights={\n",
        "#         'predictions': 0.5,  # Adjust weights if needed to balance the two losses\n",
        "#         'new_class_output': 0.5\n",
        "#     },\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Prepare data generators (make sure labels include both original and new classes)\n",
        "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "# valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# valid_generator = valid_datagen.flow_from_directory(\n",
        "#     val_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# # Train the model (you'll need to provide labels for both original and new classes)\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10,\n",
        "#     validation_data=valid_generator,\n",
        "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "#     validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        "# )\n",
        "\n",
        "# # 解冻部分卷积层进行细调\n",
        "# for layer in base_model.layers[:143]:\n",
        "#     layer.trainable = False\n",
        "# for layer in base_model.layers[143:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_fine = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10,\n",
        "#     validation_data=valid_generator,\n",
        "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "#     validation_steps=valid_generator.samples // valid_generator.batch_size\n",
        "# )\n",
        "\n",
        "# # 保存模型\n",
        "# model.save('/content/drive/MyDrive/classifier_v1_1.h5')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "k3Mi1pNvo87r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# random.seed(42)\n",
        "# np.random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # Load the pre-trained ResNet50 model, including the top classification layer\n",
        "# base_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Get the output of the penultimate layer (before the final softmax)\n",
        "# x = base_model.layers[-2].output\n",
        "\n",
        "# # Add new classification layer for the new classes\n",
        "# num_new_class = 9\n",
        "# new_class_predictions = Dense(num_new_class, activation='softmax', name='new_class_output')(x)\n",
        "\n",
        "# # Create a new model with two outputs: original 1000 classes and new 9 classes\n",
        "# model = Model(inputs=base_model.input, outputs=[base_model.output, new_class_predictions])\n",
        "\n",
        "# # Freeze all layers in the base model except the new classification layer\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "# model.get_layer('new_class_output').trainable = True  # Make the new layer trainable\n",
        "\n",
        "# # Compile the model with appropriate loss functions for both outputs\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#     loss={\n",
        "#         'predictions': 'categorical_crossentropy',  # Original 1000 classes\n",
        "#         'new_class_output': 'categorical_crossentropy'  # New 9 classes\n",
        "#     },\n",
        "#     loss_weights={\n",
        "#         'predictions': 0.5,  # Adjust weights if needed to balance the two losses\n",
        "#         'new_class_output': 0.5\n",
        "#     },\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Prepare data generators\n",
        "# # IMPORTANT: Make sure your train_generator yields labels for BOTH the original 1000 classes AND the new 9 classes.\n",
        "# # The labels should be a list or tuple of two numpy arrays, one for each output.\n",
        "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "# valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# # Example assuming 'y_original' and 'y_new' are numpy arrays containing labels for the original and new classes respectively\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# def generate_data_with_two_labels(generator, y_original, y_new):\n",
        "#     \"\"\"\n",
        "#     Yields batches of (x, [y1, y2]) where y1 and y2 are labels for the two outputs.\n",
        "#     \"\"\"\n",
        "#     while True:\n",
        "#         batch_x, batch_y = generator.next()\n",
        "#         # Assuming y_original and y_new are indexed in the same order as the generator\n",
        "#         batch_y_original = y_original[generator.index_array]\n",
        "#         batch_y_new = y_new[generator.index_array]\n",
        "#         yield batch_x, [batch_y_original, batch_y_new]\n",
        "\n",
        "# # Wrap your generator to yield both sets of labels\n",
        "# train_generator = generate_data_with_two_labels(train_generator, y_original, y_new)\n",
        "\n",
        "# valid_generator = valid_datagen.flow_from_directory(\n",
        "#     val_dir,\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# valid_generator = generate_data_with_two_labels(valid_generator, y_original_val, y_new_val)  # Provide validation labels\n",
        "# # Train the model\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10\n",
        "# )\n",
        "# validation_data = valid_generator\n",
        "# steps_per_epoch = train_generator.samples // train_generator.batch_size"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "IQ8TKU9Hp_Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random.seed(42)\n",
        "# np.random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # Load the pre-trained ResNet50 model\n",
        "# base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Freeze the base model layers\n",
        "# base_model.trainable = False\n",
        "\n",
        "# # Add a new classification head\n",
        "# x = base_model.output\n",
        "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# x = tf.keras.layers.Dense(1009, activation='softmax')(x)\n",
        "\n",
        "# # Create the new model\n",
        "# model = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Load the new dataset\n",
        "# train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#     train_dir\n",
        "# )\n",
        "\n",
        "# validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#     val_dir\n",
        "# )\n",
        "# test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#     test_dir\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "OY3yo9yHrRzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #try Pytorch\n",
        "\n",
        "# import torch\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = torch.nn.Linear(num_ftrs, 1009)\n",
        "\n",
        "# # assume we have 9 dataset classes\n",
        "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# for epoch in range(10):  # fine-tune for 10 epochs\n",
        "#     for images, labels in data_loader:\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "4B0aOkpYvphD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Data Preparing\n",
        "# from keras.utils import to_categorical\n",
        "# # Define the data directories\n",
        "# train_dir = '/content/drive/MyDrive/Birmingham/Final Project/split_data/train/'\n",
        "# val_dir = '/content/drive/MyDrive/Birmingham/Final Project/split_data/val/'\n",
        "# test_dir = '/content/drive/MyDrive/Birmingham/Final Project/split_data/test/'\n",
        "\n",
        "\n",
        "\n",
        "# # Define the number of classes\n",
        "# num_classes = 1009\n",
        "\n",
        "# # Define the image size\n",
        "# img_height, img_width = 224, 224\n",
        "\n",
        "# # Define the data augmentation\n",
        "# data_augmentation = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True\n",
        "# )\n",
        "\n",
        "# # Define the training data generator\n",
        "# train_data_gen = data_augmentation.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=(img_height, img_width),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# # Define the validation data generator\n",
        "# val_data_gen = data_augmentation.flow_from_directory(\n",
        "#     val_dir,\n",
        "#     target_size=(img_height, img_width),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# # Define the testing data generator\n",
        "# test_data_gen = data_augmentation.flow_from_directory(\n",
        "#     test_dir,\n",
        "#     target_size=(img_height, img_width),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "# # Fine-tune the ResNet50 model\n",
        "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# # Freeze the base model layers\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Compile the model\n",
        "# # model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "# model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', from_logits=True, metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# history = model.fit(\n",
        "#     train_data_gen,\n",
        "#     epochs=10,\n",
        "#     validation_data=val_data_gen,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, accuracy = model.evaluate(test_data_gen)\n",
        "# print(f'Test accuracy: {accuracy:.2f}')\n",
        "\n",
        "# # Save the model\n",
        "# model.save('resnet50_fine_tuned.h5')"
      ],
      "metadata": {
        "id": "lRkaga7z0AXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}